{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d710f4f7",
   "metadata": {},
   "source": [
    "# Anhang: Implementierung der räumlichen Analyse\n",
    "\n",
    "Dieser Anhang dokumentiert die methodisch relevanten Teile der Implementierung zur Evaluierung der Lösungskonzepte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wfs-md-intro",
   "metadata": {},
   "source": [
    "## 0. Datenbeschaffung: HU-DE via LGLN-WFS\n",
    "\n",
    "Die Hausumringe (HU-DE) wurden direkt über den öffentlichen WFS-Dienst des Landesamts für Geoinformation und Landesvermessung Niedersachsen (LGLN) bezogen. Dieser Weg wurde gewählt, weil ein Massen-Download der HU-DE aus der GDI der Deutschen Telekom zum Analysezeitpunkt noch nicht möglich war.\n",
    "\n",
    "Der WFS-Dienst liefert Features seitenweise (paginiert). Da die Gesamtzahl der Gebäude im Untersuchungsgebiet die maximale Seitengröße von 1.000 Features überschreitet, werden die Seiten in einer Schleife nacheinander abgerufen und anschließend zu einem einzigen GeoDataFrame zusammengeführt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wfs-md-single",
   "metadata": {},
   "source": [
    "### 0.1 Einzelne WFS-Seite abrufen\n",
    "\n",
    "`lade_lgln_layer` kapselt einen einzelnen paginierten WFS-Request. Die Antwort wird als temporäre GML-Datei zwischengespeichert, da `geopandas.read_file` eine Datei auf der Festplatte erwartet und nicht direkt aus einem Response-Objekt lesen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wfs-code-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Endpunkt des LGLN-WFS für vereinfachte ALKIS-Daten (Niedersachsen)\n",
    "LGLN_WFS_URL = \"https://opendata.lgln.niedersachsen.de/doorman/noauth/alkis_wfs_einfach\"\n",
    "\n",
    "\n",
    "def lade_lgln_layer(layer_name, bbox_utm32, count=1000, startindex=0):\n",
    "    \"\"\"\n",
    "    Ruft eine einzelne Seite eines LGLN-WFS-Layers ab.\n",
    "\n",
    "    Der WFS-Dienst gibt maximal 'count' Features pro Anfrage zurück.\n",
    "    Über 'startindex' kann durch die Ergebnismenge paginiert werden.\n",
    "    Die Antwort wird als temporäre GML-Datei gespeichert, da\n",
    "    geopandas.read_file eine Datei auf der Festplatte benötigt.\n",
    "\n",
    "    Args:\n",
    "        layer_name  : WFS-Typname, z. B. 'ave:GebaeudeBauwerk'\n",
    "        bbox_utm32  : Bounding Box [x_min, y_min, x_max, y_max] in EPSG:25832\n",
    "        count       : Maximale Anzahl Features pro Request \n",
    "        startindex  : Startposition für die Paginierung \n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame mit den geladenen Features oder None bei Fehler.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'SERVICE'   : 'WFS',\n",
    "        'REQUEST'   : 'GetFeature',\n",
    "        'VERSION'   : '2.0.0',\n",
    "        'TYPENAMES' : layer_name,\n",
    "        'STARTINDEX': startindex,\n",
    "        'COUNT'     : count,\n",
    "        'SRSNAME'   : 'urn:ogc:def:crs:EPSG::25832',\n",
    "        'BBOX'      : f\"{bbox_utm32[0]},{bbox_utm32[1]},{bbox_utm32[2]},{bbox_utm32[3]},\"\n",
    "                      f\"urn:ogc:def:crs:EPSG::25832\",\n",
    "        'NAMESPACES': 'xmlns(ave,http://repository.gdi-de.org/schemas/adv/produkt/alkis-vereinfacht/2.0)'\n",
    "    }\n",
    "\n",
    "\n",
    "    temp_file = tempfile.NamedTemporaryFile(mode='wb', suffix='.gml', delete=False)\n",
    "    temp_filename = temp_file.name\n",
    "\n",
    "    try:\n",
    "        response = requests.get(LGLN_WFS_URL, params=params, timeout=120)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            temp_file.close()\n",
    "            return None\n",
    "\n",
    "        temp_file.write(response.content)\n",
    "        temp_file.close()\n",
    "\n",
    "        gdf = gpd.read_file(temp_filename, engine='fiona')\n",
    "        return gdf\n",
    "\n",
    "    except Exception as e:\n",
    "        temp_file.close()\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            if os.path.exists(temp_filename):\n",
    "                os.remove(temp_filename)\n",
    "        except Exception as e:\n",
    "            logger.warning(f'Temp-Datei konnte nicht gelöscht werden: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wfs-md-all",
   "metadata": {},
   "source": [
    "### 0.2 Alle Features einer BBox laden (Paginierung)\n",
    "\n",
    "`lade_alle_features` ruft `lade_lgln_layer` wiederholt auf, bis keine weiteren Features mehr zurückgegeben werden. Gibt der Server weniger als `count` Features zurück, ist die letzte Seite erreicht und die Schleife wird beendet. Alle Teilresultate werden mit `pd.concat` zu einem einzigen GeoDataFrame zusammengeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wfs-code-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lade_alle_features(layer_name, bbox_utm32,\n",
    "                       count_per_request=1000, max_features=100000):\n",
    "    \"\"\"\n",
    "    Lädt alle Features eines WFS-Layers innerhalb einer Bounding Box\n",
    "    durch automatische Paginierung.\n",
    "\n",
    "    Die Schleife endet, wenn:\n",
    "      a) der Server weniger als count_per_request Features zurückgibt\n",
    "         (letzte Seite erreicht), oder\n",
    "      b) max_features überschritten werden (Sicherheitsabbruch).\n",
    "\n",
    "    Args:\n",
    "        layer_name        : WFS-Typname, z. B. 'ave:GebaeudeBauwerk'\n",
    "        bbox_utm32        : Bounding Box [x_min, y_min, x_max, y_max] in EPSG:25832\n",
    "        count_per_request : Features pro Seite \n",
    "        max_features      : Maximale Gesamtanzahl als Sicherheitsabbruch \n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame mit allen Features oder None, falls nichts geladen wurde.\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "    startindex = 0\n",
    "\n",
    "    logger.info(f'Starte vollständigen Abruf für {layer_name}...')\n",
    "\n",
    "    while startindex < max_features:\n",
    "        page = lade_lgln_layer(\n",
    "            layer_name, bbox_utm32,\n",
    "            count=count_per_request,\n",
    "            startindex=startindex\n",
    "        )\n",
    "\n",
    " \n",
    "        if page is None or len(page) == 0:\n",
    "            break\n",
    "\n",
    "        all_pages.append(page)\n",
    "        total_so_far = sum(len(p) for p in all_pages)\n",
    "       \n",
    "\n",
    "        if len(page) < count_per_request:\n",
    "            break\n",
    "\n",
    "        startindex += count_per_request\n",
    "\n",
    "    if not all_pages:\n",
    "        return None\n",
    "\n",
    "    result = gpd.GeoDataFrame(\n",
    "        pd.concat(all_pages, ignore_index=True),\n",
    "        crs=all_pages[0].crs\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89a77c",
   "metadata": {},
   "source": [
    "## 1. Hilfsfunktionen für die räumliche Verschneidung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21240430",
   "metadata": {},
   "source": [
    "`select_best_match` löst Mehrdeutigkeiten auf, die entstehen, wenn ein Punkt mehrere Gebäude berührt. Sie vergleicht die dokumentierte Standortadresse mit den Gebäudeadressen der Treffer und gibt das übereinstimmende Ergebnis zurück. Liegt kein Adress-Match vor, wird der erste gefundene Treffer zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_best_match(group, search_col, ref_col):\n",
    "    \"\"\"\n",
    "    Wählt bei mehreren Gebäudetreffern denjenigen aus,\n",
    "    dessen Adresse mit der Standortadresse übereinstimmt.\n",
    "    Gibt den ersten Treffer zurück, falls kein Match gefunden wird.\n",
    "    \"\"\"\n",
    "    matches = group[group[search_col] == group[ref_col]]\n",
    "    return matches.iloc[0] if len(matches) > 0 else group.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71109fb8",
   "metadata": {},
   "source": [
    "`perform_spatial_join` kapselt den GeoPandas-`sjoin`-Aufruf. Das Prädikat steuert die Art der räumlichen Beziehung: `intersects` erfasst alle Berührungen einschließlich Randpunkte, `within` erfordert die vollständige Lage innerhalb des Polygons. Bei Bedarf wird `select_best_match` gruppenweise angewendet, um je Punkt genau einen Gebäudeeintrag zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea27118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_spatial_join(left_gdf, right_gdf, predicate='intersects', match_func=None, match_cols=None, operation_name=\"Join\"):\n",
    "    \"\"\"\n",
    "    Führt einen räumlichen Join (sjoin) zwischen zwei GeoDataFrames durch.\n",
    "    predicate: 'intersects' berücksichtigt Randberührungen, 'within' erfordert vollständige Lage im Polygon.\n",
    "    Falls match_func übergeben wird, wird select_best_match gruppenweise angewendet.\n",
    "    \"\"\"\n",
    "    joined = gpd.sjoin(left_gdf, right_gdf, how='left', predicate=predicate)\n",
    "    if match_func and match_cols:\n",
    "        joined = joined.groupby(joined.index, group_keys=False).apply(match_func, **match_cols)\n",
    "    matches = joined['index_right'].notna().sum()\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b2548",
   "metadata": {},
   "source": [
    "`match_addresses` kapselt den vollständigen Adressabgleich für einen räumlichen Join. Die Methode ruft `perform_spatial_join` auf und übergibt `select_best_match` als Auflösungsstrategie, sodass bei mehreren Gebäudetreffern derjenige Treffer bevorzugt wird, dessen normalisierte Adresse mit der Standortadresse übereinstimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_addresses(self, points_gdf, buildings_gdf, point_addr_col, building_addr_col):\n",
    "    \"\"\"\n",
    "    Führt einen räumlichen Join mit adressbasierter Mehrdeutigkeitsauflösung durch.\n",
    "\n",
    "    Kombiniert perform_spatial_join mit select_best_match. Liegt ein Punkt in mehreren\n",
    "    Gebäudepolygonen, wird dasjenige Gebäude bevorzugt, dessen normalisierte Adresse\n",
    "    mit der Standortadresse übereinstimmt. Ohne Adresstrefferübereinstimmung wird der\n",
    "    erste geometrische Treffer zurückgegeben.\n",
    "\n",
    "    Args:\n",
    "        points_gdf        : GeoDataFrame der Standortpunkte (z. B. KLS, Gf-AP, HK-DE)\n",
    "        buildings_gdf     : GeoDataFrame der Gebäudepolygone\n",
    "        point_addr_col    : Spaltenname der normalisierten Adresse im points_gdf\n",
    "        building_addr_col : Spaltenname der normalisierten Adresse im buildings_gdf\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame mit den Ergebnissen des räumlichen Joins inkl. 'index_right'\n",
    "        (Gebäude-Index) und allen Attributspalten des buildings_gdf.\n",
    "    \"\"\"\n",
    "    return perform_spatial_join(\n",
    "        points_gdf,\n",
    "        buildings_gdf,\n",
    "        predicate='intersects',\n",
    "        match_func=select_best_match,\n",
    "        match_cols={\n",
    "            'search_col': point_addr_col,\n",
    "            'ref_col':    building_addr_col,\n",
    "        },\n",
    "        operation_name='Adressabgleich'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d64da0",
   "metadata": {},
   "source": [
    "## 2. Point-in-Polygon-Analyse\n",
    "\n",
    "Für jeden der 405 Standorte wird geprüft, ob KLS-Koordinate, Gf-AP-Koordinate und HK-DE innerhalb eines Gebäudepolygons liegen. Die Verschneidung erfolgt zunächst gegen die ALKIS-Gebäude. KLS-Koordinaten ohne ALKIS-Treffer werden anschließend gegen die HU-DE geprüft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebecee5e",
   "metadata": {},
   "source": [
    "### 2.1 KLS-Koordinate gegen ALKIS-Gebäude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87566fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_kls = processor.match_addresses(\n",
    "    gdf_points_25832,\n",
    "    gdf_buildings_25832,\n",
    "    'adresse_kls', #Name der spalte der normaliserten Adresse der KLS\n",
    "    'adresse_normalisiert' #Name der spalte der normaliserten Adresse des Gebäudes\n",
    ")\n",
    "joined_kls['Im_Gebaeude'] = joined_kls['index_right'].notna()\n",
    "joined_kls['BID_KLS'] = joined_kls['index_right'] #BID= BuildingID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04b055",
   "metadata": {},
   "source": [
    "### 2.2 KLS-Koordinate gegen HU-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb806c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punkte, die nicht im ALKIS-Bestand liegen, werden gegen die HU-DE-Polygone geprüft.\n",
    "gdf_points_outside = gdf_points_25832[~joined_kls['Im_Gebaeude']].copy()\n",
    "\n",
    "if len(gdf_points_outside) > 0 and len(gdf_zshh25832) > 0:\n",
    "    joined_zshh = processor.match_addresses(\n",
    "        gdf_points_outside,\n",
    "        gdf_zshh25832,\n",
    "        'adresse_kls',\n",
    "        'adresse_normalisiert'\n",
    "    )\n",
    "    joined_zshh['ImGebaeudeZSHH'] = joined_zshh['index_right'].notna()\n",
    "    joined_zshh['BID_ZSHH'] = joined_zshh['index_right']\n",
    "\n",
    "else:\n",
    "    joined_zshh = gdf_points_25832.copy()\n",
    "    joined_zshh['ImGebaeudeZSHH'] = False\n",
    "    joined_zshh['BID_ZSHH'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca558df",
   "metadata": {},
   "source": [
    "### 2.3 Gf-AP-Koordinate gegen ALKIS-Gebäude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gf-AP-Koordinaten werden individuell mit ALKIS-Gebäuden verschnitten.\n",
    "# Jede AP-Zeile bleibt erhalten, damit pro Standort mehrere APs verglichen werden können.\n",
    "joined_ap = processor.match_addresses(\n",
    "    gdf_ap,\n",
    "    gdf_buildings_25832,\n",
    "    'adresse_ap',\n",
    "    'adresse_normalisiert',\n",
    ")\n",
    "joined_ap['BID_AP'] = joined_ap['index_right']\n",
    "joined_ap['BID_from_AP'] = joined_ap['BID_AP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347c0233",
   "metadata": {},
   "source": [
    "### 2.4 HK-DE gegen ALKIS-Gebäude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cddf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HK-DE-Koordinaten werden mit ALKIS-Gebäuden verschnitten.\n",
    "joined_hauskoord = processor.match_addresses(\n",
    "    gdf_hauskoord,\n",
    "    gdf_buildings_25832,\n",
    "    'adresse_kls',\n",
    "    'adresse_normalisiert'\n",
    ")\n",
    "joined_hauskoord['BID_HK'] = joined_hauskoord['index_right']\n",
    "joined_hauskoord['Hauskoord_Im_Gebaeude'] = joined_hauskoord['BID_HK'].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967effcf",
   "metadata": {},
   "source": [
    "## 3. HK-AP-Übereinstimmungscheck\n",
    "\n",
    "Geprüft wird, ob HK-DE und Gf-AP im selben ALKIS-Gebäude liegen. Die Bedingung `Check_HK_AP_Match` ist nur dann erfüllt, wenn zusätzlich die KLS-Koordinate außerhalb des Gebäudes liegt, da nur in diesem Fall eine Korrektur über die HK-AP-Übereinstimmung methodisch relevant ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff883728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüft ob KLS außerhalb und HK-DE innerhalb eines Gebäudes liegt.\n",
    "cond_kls_out_hk_in = (\n",
    "    (result_df['Im_Gebaeude'] == False) &\n",
    "    (result_df['Hauskoord_Im_Gebaeude'] == True)\n",
    ")\n",
    "result_df['Check_KLS_out_HK_in'] = cond_kls_out_hk_in.map({True: 'Ja', False: 'Nein'})\n",
    "\n",
    "cond_hk_ap_match = pd.Series(False, index=result_df.index)\n",
    "\n",
    "# Vergleich nur für Zeilen, in denen beide Gebäude-IDs vorhanden sind.\n",
    "mask_valid = (result_df['BID_HK'].notna()) & (result_df['BID_from_AP'].notna())\n",
    "\n",
    "if mask_valid.any():\n",
    "    cond_hk_ap_match.loc[mask_valid] = (\n",
    "        cond_kls_out_hk_in.loc[mask_valid] &\n",
    "        (result_df.loc[mask_valid, 'BID_HK'] == result_df.loc[mask_valid, 'BID_from_AP'])\n",
    "    )\n",
    "\n",
    "result_df['Check_HK_AP_Match'] = cond_hk_ap_match.map({True: 'Ja', False: 'Nein'})\n",
    "result_df['HK_Status_Detail'] = result_df.apply(get_hk_status, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29663b4",
   "metadata": {},
   "source": [
    "## 4. Fehlerkategorisierung\n",
    "\n",
    "Ein Standort gilt als Problemfall, wenn die KLS-Koordinate nicht dem dokumentierten Gebäude zugeordnet werden kann. Es werden vier Fehlerkategorien unterschieden, die sich gegenseitig ausschließen. `Ist_Problemfall` fasst alle vier zu einem binären Flag zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"Problem_Status\"] = \"OK\"\n",
    "\n",
    "im_gebaeude = result_df[\"Im_Gebaeude\"].fillna(False).astype(bool)\n",
    "ap_im_gebaeude = result_df[\"AP_Im_Gebaeude\"].fillna(False).astype(bool)\n",
    "\n",
    "if \"KLS_Gebaeude_hat_APs\" in result_df.columns:\n",
    "    kls_hat_aps = result_df[\"KLS_Gebaeude_hat_APs\"].fillna(False).astype(bool)\n",
    "else:\n",
    "    kls_hat_aps = pd.Series(False, index=result_df.index)\n",
    "\n",
    "bid_kls = result_df[\"BID_KLS\"]\n",
    "\n",
    "if 'BID_AP_Specific' in result_df.columns:\n",
    "    bid_ap = result_df[\"BID_AP_Specific\"]\n",
    "else:\n",
    "    bid_ap = result_df[\"BID_from_AP\"]\n",
    "\n",
    "mask_both_exist = bid_kls.notna() & bid_ap.notna()\n",
    "\n",
    "bid_unequal = pd.Series(False, index=result_df.index)\n",
    "bid_unequal.loc[mask_both_exist] = (\n",
    "    bid_kls.loc[mask_both_exist].astype(str) != bid_ap.loc[mask_both_exist].astype(str)\n",
    ")\n",
    "\n",
    "# Fehlerkategorien: P1a = KLS außerhalb, AP innen; P1b = beide außerhalb;\n",
    "# P2 = verschiedene Gebäude; P3 = fremder AP im KLS-Gebäude\n",
    "cond_p1a = (~im_gebaeude) & ap_im_gebaeude\n",
    "cond_p1b = (~im_gebaeude) & (~ap_im_gebaeude)\n",
    "cond_falsches_gebaeude_basis = im_gebaeude & mask_both_exist & bid_unequal\n",
    "cond_p3 = cond_falsches_gebaeude_basis & kls_hat_aps\n",
    "cond_p2 = cond_falsches_gebaeude_basis & ~cond_p3\n",
    "\n",
    "result_df.loc[cond_p1a, \"Problem_Status\"] = \"PROBLEM KLS außerhalb, AP im Gebäude\"\n",
    "result_df.loc[cond_p1b, \"Problem_Status\"] = \"PROBLEM KLS und AP außerhalb\"\n",
    "result_df.loc[cond_p2, \"Problem_Status\"] = \"PROBLEM Falsches Gebäude\"\n",
    "result_df.loc[cond_p3, \"Problem_Status\"] = \"PROBLEM KLS mit fremdem AP im Gebäude\"\n",
    "\n",
    "result_df[\"Ist_Problemfall\"] = 0\n",
    "result_df.loc[cond_p1a | cond_p1b | cond_p2 | cond_p3, \"Ist_Problemfall\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a72b4",
   "metadata": {},
   "source": [
    "## 5. Lösungsweg-Prüfung und Priorisierung\n",
    "\n",
    "Für jeden Problemfall wird geprüft, welches der Lösungskonzepte greift. Die Konzepte werden zunächst unabhängig voneinander bewertet und dann in einer festen Prioritätsreihenfolge zu einem eindeutigen Lösungsweg zusammengeführt. Jeder Standort erhält genau einen Lösungsweg oder den Status 'Ungelöst'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_kls_safe = result_df['PID_KLS'].fillna(-9999).astype('Int64') if 'PID_KLS' in result_df.columns else pd.Series(-9999, index=result_df.index)\n",
    "pid_ap_safe  = result_df['PID_AP'].fillna(-9999).astype('Int64') if 'PID_AP' in result_df.columns else pd.Series(-9999, index=result_df.index)\n",
    "bid_hk_safe  = result_df['BID_HK'].fillna(-9999).astype('Int64') if 'BID_HK' in result_df.columns else pd.Series(-9999, index=result_df.index)\n",
    "bid_ap_safe  = result_df['BID_from_AP'].fillna(-9999).astype('Int64') if 'BID_from_AP' in result_df.columns else pd.Series(-9999, index=result_df.index)\n",
    "\n",
    "mask_problem = (result_df['Ist_Problemfall'] == 1)\n",
    "\n",
    "# Flurstück-Logik: lösbar wenn KLS und Gf-AP auf demselben Flurstück liegen und nHK-DE = 1.\n",
    "if {'PID_KLS', 'PID_AP', 'Im_Flurstueck', 'Anzahl_HK_Geometrisch'}.issubset(result_df.columns):\n",
    "    result_df['Check_CanSolve_Flurstueck'] = (\n",
    "        mask_problem &\n",
    "        (result_df['Im_Flurstueck'] == True) &\n",
    "        (result_df['PID_KLS'].notna()) &\n",
    "        (result_df['PID_AP'].notna()) &\n",
    "        (pid_kls_safe == pid_ap_safe) &\n",
    "        (result_df['Anzahl_HK_Geometrisch'] == 1)\n",
    "    )\n",
    "else:\n",
    "    result_df['Check_CanSolve_Flurstueck'] = False\n",
    "\n",
    "# HU-DE-Integration: lösbar wenn die KLS-Koordinate innerhalb eines HU-DE-Polygons liegt.\n",
    "if 'ImGebaeudeZSHH' in result_df.columns:\n",
    "    result_df['Check_CanSolve_ZSHH'] = (\n",
    "        mask_problem &\n",
    "        (result_df['ImGebaeudeZSHH'] == True)\n",
    "    )\n",
    "else:\n",
    "    result_df['Check_CanSolve_ZSHH'] = False\n",
    "\n",
    "# HU-DE via HK+AP: lösbar wenn HK-DE und mindestens ein Gf-AP im selben HU-DE-Gebäude liegen.\n",
    "if {'BIDZSHH_HK', 'BID_from_AP_ZSHH', 'Hauskoord_Im_GebaeudeZSHH'}.issubset(result_df.columns):\n",
    "\n",
    "    def check_zshh_hkap_match(group):\n",
    "        \"\"\"Prüft ob mindestens ein Gf-AP derselben KLS-ID im gleichen HU-DE-Gebäude wie die HK-DE liegt.\"\"\"\n",
    "        bid_hk_zshh = group['BIDZSHH_HK'].iloc[0] if group['BIDZSHH_HK'].notna().any() else None\n",
    "        hk_in_zshh  = group['Hauskoord_Im_GebaeudeZSHH'].iloc[0] if group['Hauskoord_Im_GebaeudeZSHH'].notna().any() else False\n",
    "        kls_in_zshh = group['ImGebaeudeZSHH'].iloc[0] if group['ImGebaeudeZSHH'].notna().any() else True\n",
    "\n",
    "        if not hk_in_zshh or pd.isna(bid_hk_zshh) or kls_in_zshh:\n",
    "            return pd.Series(False, index=group.index)\n",
    "\n",
    "        ap_matches_hk = (group['BID_from_AP_ZSHH'] == bid_hk_zshh) & group['BID_from_AP_ZSHH'].notna()\n",
    "        return pd.Series(ap_matches_hk.any(), index=group.index)\n",
    "\n",
    "    result_df['Check_CanSolve_ZSHH_HKAP'] = False\n",
    "    if mask_problem.any():\n",
    "        problem_rows = result_df[mask_problem]\n",
    "        matched = problem_rows.groupby('KLS_ID', group_keys=False).apply(check_zshh_hkap_match)\n",
    "        result_df.loc[mask_problem, 'Check_CanSolve_ZSHH_HKAP'] = matched\n",
    "else:\n",
    "    result_df['Check_CanSolve_ZSHH_HKAP'] = False\n",
    "\n",
    "# HK-AP-Übereinstimmung (ALKIS): lösbar wenn HK-DE und Gf-AP im selben ALKIS-Gebäude liegen.\n",
    "if {'BID_HK', 'BID_from_AP', 'Hauskoord_Im_Gebaeude'}.issubset(result_df.columns):\n",
    "    result_df['Check_CanSolve_HK_AP'] = (\n",
    "        mask_problem &\n",
    "        (result_df['Hauskoord_Im_Gebaeude'] == True) &\n",
    "        (result_df['BID_HK'].notna()) &\n",
    "        (result_df['BID_from_AP'].notna()) &\n",
    "        (bid_hk_safe == bid_ap_safe)\n",
    "    )\n",
    "else:\n",
    "    result_df['Check_CanSolve_HK_AP'] = False\n",
    "\n",
    "# Fremder Gf-AP identifizieren.\n",
    "result_df['Check_CanSolve_FremdAP'] = (mask_problem & cond_p3) if 'cond_p3' in locals() else False\n",
    "\n",
    "# Gf-AP-Konzept: lösbar wenn KLS außerhalb liegt, der Gf-AP geometrisch innerhalb eines Gebäudes liegt und die in Megaplan dokumentierte Adresse des Gf-AP mit der amtlichen ALKIS-Adresse \n",
    "# dieses Gebäudes übereinstimmt (keine fehlerhafte Dokumentation).\n",
    "if {'AP_Im_Gebaeude', 'adresse_ap', 'Adresse_Gebaeude_AP'}.issubset(result_df.columns):\n",
    "    cond_ap_adresse_korrekt = (\n",
    "        result_df['adresse_ap'].notna() &\n",
    "        result_df['Adresse_Gebaeude_AP'].notna() &\n",
    "        (\n",
    "            result_df['adresse_ap'].astype(str).str.strip() ==\n",
    "            result_df['Adresse_Gebaeude_AP'].astype(str).str.strip()\n",
    "        )\n",
    "    )\n",
    "    result_df['Check_CanSolve_GfAP'] = (\n",
    "        mask_problem &\n",
    "        (~result_df['Im_Gebaeude'].fillna(False).astype(bool)) &\n",
    "        (result_df['AP_Im_Gebaeude'].fillna(False).astype(bool)) &\n",
    "        cond_ap_adresse_korrekt\n",
    "    )\n",
    "else:\n",
    "    result_df['Check_CanSolve_GfAP'] = False\n",
    "\n",
    "# Priorisierung: Flurstück > HU-DE > HK+AP (ALKIS) > HU-DE via HK+AP > Gf-AP-Konzept\n",
    "result_df['Loesungsweg'] = 'OK'\n",
    "result_df.loc[mask_problem, 'Loesungsweg'] = 'Ungelöst'\n",
    "\n",
    "mask_p1 = result_df['Check_CanSolve_Flurstueck']\n",
    "result_df.loc[mask_p1, 'Loesungsweg'] = 'Gelöst: Flurstück'\n",
    "\n",
    "mask_p2 = result_df['Check_CanSolve_ZSHH'] & ~mask_p1\n",
    "result_df.loc[mask_p2, 'Loesungsweg'] = 'Gelöst: HU-DE'\n",
    "\n",
    "mask_p3 = result_df['Check_CanSolve_HK_AP'] & ~mask_p1 & ~mask_p2\n",
    "result_df.loc[mask_p3, 'Loesungsweg'] = 'Gelöst: HK-DE und Gf-AP im selben Gebäude'\n",
    "\n",
    "mask_p4 = result_df['Check_CanSolve_ZSHH_HKAP'] & ~mask_p1 & ~mask_p2 & ~mask_p3\n",
    "result_df.loc[mask_p4, 'Loesungsweg'] = 'Gelöst: HU-DE via HK+AP'\n",
    "\n",
    "mask_p5 = result_df['Check_CanSolve_GfAP'] & ~mask_p1 & ~mask_p2 & ~mask_p3 & ~mask_p4\n",
    "result_df.loc[mask_p5, 'Loesungsweg'] = 'Gelöst: MP-Konzept'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b382b1",
   "metadata": {},
   "source": [
    "Nach der Lösungsweg-Zuweisung enthält `result_df` für jeden KLS-Standort eine Zeile pro Gf-AP. Für die weiteren Auswertungen wird je Standort genau ein repräsentativer Eintrag benötigt. Die Auswahl folgt einer dreistufigen Priorität: Ein Gf-AP, der geometrisch innerhalb eines Gebäudes liegt, wird einem außenliegenden vorgezogen. Bei Gleichstand gewinnt der Gf-AP mit der geringsten metrischen Distanz zur KLS-Koordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c86056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AP_Im_Gebaeude als Bool sicherstellen (True=1 > False=0 bei absteigender Sortierung)\n",
    "result_df['AP_Im_Gebaeude'] = result_df['AP_Im_Gebaeude'].fillna(False).astype(bool)\n",
    "\n",
    "# Distanz_m mit Fallback befüllen, falls Spalte fehlt\n",
    "if 'Distanz_m' not in result_df.columns:\n",
    "    result_df['Distanz_m'] = 9999\n",
    "\n",
    "# Sortierung: KLS_ID aufsteigend, AP_Im_Gebaeude absteigend (\"Im Gebäude\" gewinnt),\n",
    "# Distanz_m aufsteigend (kleinere Distanz gewinnt bei Gleichstand)\n",
    "result_df = result_df.sort_values(\n",
    "    by=['KLS_ID', 'AP_Im_Gebaeude', 'Distanz_m'],\n",
    "    ascending=[True, False, True]\n",
    ")\n",
    "\n",
    "# Reduktion auf einen repräsentativen Eintrag pro KLS-Standort\n",
    "result_df = result_df.drop_duplicates(subset='KLS_ID', keep='first').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edc416",
   "metadata": {},
   "source": [
    "## 6. Erkennung fehlerhaft dokumentierter Gf-APs\n",
    "\n",
    "Ein Gf-AP gilt als fehlerhaft dokumentiert, wenn er geometrisch in einem Gebäude liegt, dessen Adresse nicht mit der Adresse des HK-DE-Gebäudes übereinstimmt. Ergänzend wird geprüft, ob eine andere HK-DE im AP-Gebäude existiert, was auf eine Verwechslung zweier Standorte hindeuten kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Check_AP_Falsches_Gebaeude'] = 'Nein'\n",
    "result_df['Andere_HK_Im_AP_Gebaeude'] = 'Nein'\n",
    "\n",
    "# Ein Gf-AP gilt als fehlerhaft dokumentiert, wenn HK-DE und Gf-AP in unterschiedlichen Gebäuden liegen.\n",
    "hk_im_gebaeude_mit_adresse = (\n",
    "    (result_df['Hauskoord_Im_Gebaeude'] == True) &\n",
    "    (result_df['Adresse_Gebaeude_HK'].notna())\n",
    ")\n",
    "\n",
    "ap_im_anderen_gebaeude = (\n",
    "    (result_df['Adresse_Gebaeude_AP'].notna()) &\n",
    "    (result_df['Adresse_Gebaeude_HK'].astype(str).str.strip() !=\n",
    "     result_df['Adresse_Gebaeude_AP'].astype(str).str.strip())\n",
    ")\n",
    "\n",
    "ap_falsches_gebaeude = hk_im_gebaeude_mit_adresse & ap_im_anderen_gebaeude\n",
    "result_df.loc[ap_falsches_gebaeude, 'Check_AP_Falsches_Gebaeude'] = 'Ja'\n",
    "\n",
    "# Prüft zusätzlich, ob eine andere HK-DE im AP-Gebäude existiert (Hinweis auf Vertauschung).\n",
    "if ap_falsches_gebaeude.any():\n",
    "    hk_in_gebaeude = result_df[\n",
    "        (result_df['Hauskoord_Im_Gebaeude'] == True) &\n",
    "        (result_df['Adresse_Gebaeude_HK'].notna())\n",
    "    ].copy()\n",
    "\n",
    "    hk_pro_gebaeude = hk_in_gebaeude.groupby('Adresse_Gebaeude_HK')['KLS_ID'].apply(set).to_dict()\n",
    "\n",
    "    for idx in result_df[ap_falsches_gebaeude].index:\n",
    "        eigene_kls_id = result_df.loc[idx, 'KLS_ID']\n",
    "        ap_gebaeude_adresse = result_df.loc[idx, 'Adresse_Gebaeude_AP']\n",
    "\n",
    "        if pd.notna(ap_gebaeude_adresse) and ap_gebaeude_adresse in hk_pro_gebaeude:\n",
    "            andere_hks = hk_pro_gebaeude[ap_gebaeude_adresse] - {eigene_kls_id}\n",
    "            if len(andere_hks) > 0:\n",
    "                result_df.loc[idx, 'Andere_HK_Im_AP_Gebaeude'] = 'Ja'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "versatz-md-intro",
   "metadata": {},
   "source": [
    "## 7. Versatz-Analyse (Nearest-Neighbor-Distanzen)\n",
    "\n",
    "`compute_versatz_analysis` berechnet für jeden Standort die metrische Distanz zur nächstgelegenen Gebäudegeometrie mittels `gpd.sjoin_nearest`. Die Funktion klassifiziert das Ergebnis anschließend in drei Kategorien:\n",
    "\n",
    "- **Im Polygon (OK):** Die KLS-Koordinate liegt innerhalb eines ALKIS-Gebäudepolygons.\n",
    "- **Verdacht Digitalisierungsversatz (<= 3 m):** Die Koordinate liegt knapp außerhalb, was auf einen systematischen Digitalisierungsversatz hinweist.\n",
    "- **Falschverortung (> 3 m):** Die Koordinate liegt deutlich außerhalb jedes Gebäudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "versatz-code-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_versatz_analysis(points_gdf, buildings_gdf, result_df,\n",
    "                             klsid_col='KLSID',\n",
    "                             in_building_col='ImGebaeude',\n",
    "                             building_addr_col='adresse_normalisiert',\n",
    "                             schwellenwert_m=3.0):\n",
    "    \"\"\"\n",
    "    Berechnet die metrische Distanz jeder KLS-Koordinate zum nächstgelegenen\n",
    "    ALKIS-Gebäudepolygon und klassifiziert den Versatzstatus.\n",
    "\n",
    "    Vorgehen:\n",
    "      1. gpd.sjoin_nearest sucht für jeden Punkt das geometrisch nächste Gebäude\n",
    "         und liefert die Distanz in Metern.\n",
    "      2. Duplikate (Punkt hat identischen Abstand zu zwei Gebäuden) werden durch\n",
    "         Behalten des ersten Treffers aufgelöst.\n",
    "      3. Klassifizierung nach Schwellenwert:\n",
    "           - 'Im Polygon (OK)'                  : Punkt bereits als ImGebaeude=True bekannt\n",
    "           - 'Verdacht Digitalisierungsversatz'  : 0.01 m <= Distanz <= schwellenwert_m\n",
    "           - 'Falschverortung'                   : Distanz > schwellenwert_m\n",
    "\n",
    "    Args:\n",
    "        points_gdf        : GeoDataFrame der KLS-Punkte \n",
    "        buildings_gdf     : GeoDataFrame der ALKIS-Gebäudepolygone\n",
    "        result_df         : resultdf, in das die neuen Spalten geschrieben werden\n",
    "        klsid_col         : Name der KLS-ID-Spalte\n",
    "        in_building_col   : Name der Bool-Spalte 'Punkt im Gebäude' \n",
    "        building_addr_col : Name der Adressspalte in buildings_gdf\n",
    "        schwellenwert_m   : Distanz-Schwellenwert in Metern \n",
    "\n",
    "    Returns:\n",
    "        result_df mit drei neuen Spalten:\n",
    "          - 'DistanzzuAdressPolygon' : Distanz in Metern zum nächsten Gebäude\n",
    "          - 'VersatzStatus'           : Klassifizierung (s.o.)\n",
    "          - 'AdresseNaechstesGebaeude': Adresse des nächsten Gebäudes\n",
    "    \"\"\"\n",
    "\n",
    "    points_work = points_gdf.copy()\n",
    "    bldgs_work  = buildings_gdf.copy()\n",
    "\n",
    "\n",
    "    def _unpack_addr(val):\n",
    "        if isinstance(val, (set, list, tuple)):\n",
    "            return str(list(val)[0]) if len(val) > 0 else ''\n",
    "        return str(val)\n",
    "\n",
    "    if building_addr_col in bldgs_work.columns:\n",
    "        bldgs_work['adresse_nearest_display'] = (\n",
    "            bldgs_work[building_addr_col].apply(_unpack_addr)\n",
    "        )\n",
    "    else:\n",
    "        bldgs_work['adresse_nearest_display'] = 'Keine Adresse'\n",
    "\n",
    "\n",
    "    # distance_col speichert die euklidische Distanz in Metern\n",
    "    joined_nearest = gpd.sjoin_nearest(\n",
    "        points_work,\n",
    "        bldgs_work[['geometry', 'adresse_nearest_display']],\n",
    "        how='left',\n",
    "        distance_col='dist_nearest'\n",
    "    )\n",
    "\n",
    "    joined_nearest = joined_nearest.drop_duplicates(\n",
    "        subset=klsid_col, keep='first'\n",
    "    )\n",
    "\n",
    "\n",
    "    dist_map = joined_nearest.set_index(klsid_col)['dist_nearest']\n",
    "    addr_map = joined_nearest.set_index(klsid_col)['adresse_nearest_display']\n",
    "\n",
    "    result_df['DistanzzuAdressPolygon'] = result_df[klsid_col].map(dist_map)\n",
    "    result_df['AdresseNaechstesGebaeude'] = result_df[klsid_col].map(addr_map)\n",
    "\n",
    "    # Punkte, die bereits als 'ImGebaeude=True' erkannt wurden, erhalten die Distanz 0.0 \n",
    "    result_df.loc[result_df[in_building_col] == True,\n",
    "                  'DistanzzuAdressPolygon'] = 0.0\n",
    "\n",
    "    def _classify_versatz(row):\n",
    "        dist   = row['DistanzzuAdressPolygon']\n",
    "        imgeb  = row.get(in_building_col, False)\n",
    "\n",
    "        if imgeb:\n",
    "            return 'Im Polygon (OK)'\n",
    "\n",
    "        if pd.isna(dist):\n",
    "            return 'Kein Gebäude in der Nähe gefunden'\n",
    "\n",
    "        if dist < 0.01:\n",
    "            return 'Im Polygon (OK)'\n",
    "\n",
    "        if dist <= schwellenwert_m:\n",
    "            return f'Verdacht Digitalisierungsversatz (<={schwellenwert_m:.0f}m)'\n",
    "\n",
    "        return f'Falschverortung (>{schwellenwert_m:.0f}m)'\n",
    "\n",
    "    result_df['VersatzStatus'] = result_df.apply(_classify_versatz, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flur-md-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Flurstücksverschneidung\n",
    "\n",
    "> **Hinweis zur Einordnung:** Dieser Abschnitt implementiert das in Kapitel 4.3 konzipierte Verschneidungsverfahren für zusammenhängende Flurstücke. Das Ablaufdiagramm des vollständigen Algorithmus befindet sich im Anhang.\n",
    "\n",
    "\n",
    "\n",
    "**Designentscheidung:** Das Verfahren basiert bewusst auf rein geometrischen Verschneidungsoperationen und verzichtet auf adressbasiertes Matching, da das Attribut `Lagebezeichnung` in den ALKIS-Flurstücksdaten qualitativ inkonsistent ist (teils vollständige Adresse, teils nur Straßenname, teils leer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flur-code-agg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_parcels_per_building(\n",
    "    gdf_buildings: gpd.GeoDataFrame,\n",
    "    gdf_parcels: gpd.GeoDataFrame,\n",
    "    min_building_fraction: float = 0.20\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Aggregiert Flurstücke pro Gebäude (20 %-Regel) und behält alle\n",
    "    nicht zugeordneten Flurstücke unverändert bei.\n",
    "\n",
    "    Vorgehen:\n",
    "      1. gpd.overlay (Intersection) berechnet die Schnittfläche\n",
    "         zwischen jedem Gebäude und jedem Flurstück.\n",
    "      2. Die 20 %-Regel filtert Flurstücke mit zu geringer Überdeckung.\n",
    "      3. Bei Konflikt (Flurstück unter mehreren Gebäuden) gewinnt das\n",
    "         Gebäude mit der größten Schnittfläche.\n",
    "      4. Valide Flurstücke werden pro Gebäude per unary_union verschmolzen.\n",
    "      5. Übrige Flurstücke werden ohne Verschmelzung angehängt.\n",
    "\n",
    "    Args:\n",
    "        gdf_buildings         : ALKIS-Gebäudepolygone \n",
    "        gdf_parcels           : ALKIS-Flurstücke \n",
    "        min_building_fraction : 20 %-Schwellenwert \n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame mit verschmolzenen Flurstücken (hat_gebaeude=True)\n",
    "        und übrigen Einzel-Flurstücken (hat_gebaeude=False).\n",
    "        Neue Spalten: bid, anzahl_flurstuecke, hat_gebaeude.\n",
    "    \"\"\"\n",
    "\n",
    "    buildings = gdf_buildings.copy().reset_index(drop=True)\n",
    "    buildings['bid']    = buildings.index\n",
    "    buildings['b_area'] = buildings.geometry.area\n",
    "\n",
    "    parcels = gdf_parcels.copy().reset_index(drop=True)\n",
    "    parcels['pid'] = parcels.index\n",
    "\n",
    "    # Räumliche Verschneidung (Intersection)\n",
    "\n",
    "    overlay = gpd.overlay(\n",
    "        buildings[['bid', 'b_area', 'geometry']],\n",
    "        parcels[['pid', 'geometry']],\n",
    "        how='intersection',\n",
    "        keep_geom_type=True,\n",
    "        make_valid=True\n",
    "    )\n",
    "\n",
    "    building_to_parcels = {}\n",
    "    processed_pids      = set()\n",
    "\n",
    "    if not overlay.empty:\n",
    "        overlay['intersection_area'] = overlay.geometry.area\n",
    "        overlay['frac'] = overlay['intersection_area'] / overlay['b_area']\n",
    "\n",
    "        # 20 %-Regel anwenden\n",
    "        valid = overlay[overlay['frac'] >= min_building_fraction].copy()\n",
    "\n",
    "        # Konfliktlösung: Bei Flurstück unter mehreren Gebäuden gewinnt das Gebäude mit der größten Schnittfläche\n",
    "        valid = valid.sort_values('intersection_area', ascending=False)\n",
    "        valid_unique = valid.drop_duplicates(subset=['pid'], keep='first')\n",
    "\n",
    "        building_to_parcels = valid_unique.groupby('bid')['pid'].apply(set).to_dict()\n",
    "        processed_pids      = set(valid_unique['pid'].unique())\n",
    "\n",
    "\n",
    "\n",
    "    # Flurstücke pro Gebäude verschmelzen\n",
    "\n",
    "    parcel_cols = ['flstkennz', 'gemarkung', 'flur', 'lagebeztxt']\n",
    "    result_rows = []\n",
    "\n",
    "    for bid, pids in building_to_parcels.items():\n",
    "        b_row    = buildings.loc[bid]\n",
    "        p_subset = parcels[parcels['pid'].isin(pids)]\n",
    "        if p_subset.empty:\n",
    "            continue\n",
    "\n",
    "        # Union-Operation eliminiert interne Flurstücksgrenzen\n",
    "        merged_geom = unary_union(p_subset.geometry.tolist())\n",
    "\n",
    "        entry = {\n",
    "            'bid'               : bid,\n",
    "            'anzahl_flurstuecke': len(pids),\n",
    "            'hat_gebaeude'      : True,\n",
    "            'geometry'          : merged_geom\n",
    "        }\n",
    "        # Flurstücks-Attribute zusammenfassen (Duplikate entfernen)\n",
    "        for col in parcel_cols:\n",
    "            if col in p_subset.columns:\n",
    "                vals = {str(x).strip() for x in p_subset[col] if pd.notna(x)}\n",
    "                entry[col] = ', '.join(sorted(vals)) if vals else None\n",
    "\n",
    "        result_rows.append(entry)\n",
    "\n",
    "    gdf_merged = gpd.GeoDataFrame(result_rows, crs=parcels.crs)\n",
    "\n",
    "    # Übrige Flurstücke ohne Gebäudezuordnung anhängen\n",
    "\n",
    "    leftovers = parcels[~parcels['pid'].isin(processed_pids)].copy()\n",
    "    leftovers['bid']                = None\n",
    "    leftovers['anzahl_flurstuecke'] = 1\n",
    "    leftovers['hat_gebaeude']       = False\n",
    "\n",
    "\n",
    "    # Spalten angleichen, damit pd.concat keine Fehler wirft\n",
    "    for c in gdf_merged.columns:\n",
    "        if c != 'geometry' and c not in leftovers.columns:\n",
    "            leftovers[c] = None\n",
    "\n",
    "    # Finales GeoDataFrame zusammenführen\n",
    "    final_gdf = gpd.GeoDataFrame(\n",
    "        pd.concat(\n",
    "            [gdf_merged, leftovers[[*gdf_merged.columns]]],\n",
    "            ignore_index=True\n",
    "        ),\n",
    "        geometry='geometry',\n",
    "        crs=parcels.crs\n",
    "    )\n",
    "\n",
    "    return final_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
